{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[0]: Bibliotecas\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]: Funcoes Gerais  \n",
    "def read_csv():\n",
    "    df = pd.read_csv('pantanal.csv',',')\n",
    "    \n",
    "    #df['riscofogo'] = df['riscofogo'].interpolate(method='linear')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def cv_score(score):\n",
    "    rmse = np.sqrt(-score)\n",
    "    return (rmse)\n",
    "\n",
    "\n",
    "def get_transformer():\n",
    "    \n",
    "    integer_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    return integer_transformer, numeric_transformer,categorical_transformer\n",
    "\n",
    "\n",
    "def prep_target(y,y_train, y_test):\n",
    "    \n",
    "    num_target = y.select_dtypes(\"float64\").columns\n",
    "\n",
    "\n",
    "    num_transf = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', num_transf, num_target)])\n",
    "    \n",
    "    transf = preprocessor.fit(y)\n",
    "    \n",
    "    y_train = transf.transform(y_train)\n",
    "    y_test = transf.transform(y_test)\n",
    "    \n",
    "    return y_train, y_test\n",
    "\n",
    "\n",
    "def prep_pipeline(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30,random_state=SEED)\n",
    "    \n",
    "    int_features = X.select_dtypes(\"int64\").columns\n",
    "    num_features = X.select_dtypes(\"float64\").columns\n",
    "    cat_features = X.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    \n",
    "    int_transf,num_transf,cat_transf = get_transformer()\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('int', int_transf, int_features),\n",
    "        ('num', num_transf, num_features),\n",
    "        ('cat', cat_transf, cat_features)])\n",
    "    \n",
    "    transf = preprocessor.fit(X)\n",
    "    \n",
    "    X_train_prep = transf.transform(X_train)\n",
    "    X_test_prep = transf.transform(X_test)\n",
    "    \n",
    "    y_train, y_test = prep_target(y,y_train, y_test)\n",
    "    \n",
    "    return X_train_prep, X_test_prep, y_train, y_test,preprocessor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]: Grid Search Model\n",
    "def get_decisiontree_regressor(X_train,y_train):\n",
    "    dt = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "    params_dt = {\n",
    "        'max_features':['auto','sqrt','log2'],\n",
    "        'max_depth':[5,8,10,15,20,25,30],\n",
    "        'min_samples_split':[5,8,10],\n",
    "        'min_samples_leaf':[2,4]\n",
    "    }\n",
    "    \n",
    "\n",
    "    grid_dt = GridSearchCV(estimator = dt, \n",
    "                           param_grid = params_dt,\n",
    "                           scoring ='neg_mean_squared_error',\n",
    "                           cv = 3, \n",
    "                           verbose = 1,\n",
    "                           n_jobs = -1)\n",
    "    \n",
    "    grid_dt.fit(X_train, y_train.ravel())\n",
    "    print('CV Score for best Decision Tree Regressor model: {:.3f}'.format(cv_score(grid_dt.best_score_)))\n",
    "    best_model_dt = grid_dt.best_estimator_\n",
    "    return best_model_dt\n",
    "\n",
    "def get_linear_regressor(X_train,y_train):\n",
    "    linear = LinearRegression()\n",
    "\n",
    "    params_linear = {\n",
    "    }\n",
    "    \n",
    "\n",
    "    grid_linear = GridSearchCV(estimator = linear, \n",
    "                           param_grid = params_linear,\n",
    "                           scoring ='neg_mean_squared_error',\n",
    "                           cv = 3, \n",
    "                           verbose = 1,\n",
    "                           n_jobs = -1)\n",
    "    \n",
    "    grid_linear.fit(X_train, y_train.ravel())\n",
    "    print('CV Score for best Linear Regressor model: {:.3f}'.format(cv_score(grid_linear.best_score_)))\n",
    "    best_model_linear = grid_linear.best_estimator_\n",
    "    return best_model_linear\n",
    "\n",
    "\n",
    "def get_ridge_regression(X_train,y_train):\n",
    "    ridge = Ridge(random_state=0)\n",
    "\n",
    "\n",
    "    params_ridge = {\n",
    "        'alpha': [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, \n",
    "                  1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, \n",
    "                  18, 20, 30, 50, 75, 100],\n",
    "        'solver': ['auto','cholesky']\n",
    "    }\n",
    "    \n",
    "    \n",
    "    grid_ridge = GridSearchCV(estimator = ridge,\n",
    "                           param_grid = params_ridge,\n",
    "                           scoring ='neg_mean_squared_error',\n",
    "                           cv = 3,\n",
    "                           verbose = 1,\n",
    "                           n_jobs = -1)\n",
    "    \n",
    "    grid_ridge.fit(X_train, y_train.ravel())\n",
    "    print('CV Score for best Linear Ridge Regressor model: {:.3f}'.format(cv_score(grid_ridge.best_score_)))\n",
    "    best_model_linear = grid_ridge.best_estimator_\n",
    "    return best_model_linear\n",
    "\n",
    "\n",
    "def get_svr_regressor(X_train,y_train):\n",
    "    \n",
    "    svr = LinearSVR()\n",
    "    \n",
    "    params_svr = {\n",
    "        'epsilon': [1.5,3,5], \n",
    "        'C': [1,5,7,10],\n",
    "        'tol':[1e-9,1e-7,1e-5],\n",
    "        'random_state': [42],\n",
    "        'max_iter': [5000]\n",
    "    }\n",
    "    \n",
    "    grid_svr = GridSearchCV(estimator = svr,\n",
    "                           param_grid = params_svr,\n",
    "                           scoring ='neg_mean_squared_error',\n",
    "                           cv = 3,\n",
    "                           verbose = 1,\n",
    "                           n_jobs = -1)\n",
    "    \n",
    "    grid_svr.fit(X_train, y_train.ravel())\n",
    "    print('CV Score for best SVR Regressor model: {:.3f}'.format(cv_score(grid_svr.best_score_)))\n",
    "    best_model = grid_svr.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "def get_rf_regressor(X_train,y_train):\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state= 0)\n",
    "    \n",
    "    params_rf = {\n",
    "        'n_estimators': [400,500,700],\n",
    "        'max_features':['auto','sqrt'],\n",
    "        'max_depth':[5,8,10,15,20,25,30],\n",
    "        'min_samples_split':[5,8,10],\n",
    "        'min_samples_leaf':[2,4]\n",
    "    }\n",
    "    \n",
    "    grid_rf = GridSearchCV(estimator = rf,\n",
    "                           param_grid = params_rf, \n",
    "                           scoring ='neg_mean_squared_error',\n",
    "                           cv = 3, \n",
    "                           verbose = 1,\n",
    "                           n_jobs = -1)\n",
    "    \n",
    "    grid_rf.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    print('CV Score for best Random Forest Regressor model {:.3f}'.format(cv_score(grid_rf.best_score_)))\n",
    "    best_model = grid_rf.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def get_extratree_regressor(X_train,y_train):\n",
    "    \n",
    "    extratrees = ExtraTreesRegressor(random_state= 0)\n",
    "    \n",
    "    params_extratrees = {\n",
    "    }\n",
    "    \n",
    "    grid_extratrees = GridSearchCV(estimator = extratrees,\n",
    "                       param_grid = params_extratrees,\n",
    "                       scoring ='neg_mean_squared_error',\n",
    "                       cv = 3,\n",
    "                       verbose = 1,\n",
    "                       n_jobs = -1)\n",
    "    \n",
    "    grid_extratrees.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    print('CV Score for best Extra Trees Regressor model {:.3f}'.format(cv_score(grid_extratrees.best_score_)))\n",
    "    best_model = grid_extratrees.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "\n",
    "\n",
    "def get_gbr_regressor(X_train,y_train):\n",
    "\n",
    "    gbr = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "    params_gbr = {\n",
    "        'n_estimators': [700],\n",
    "        'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "        'max_features': ['auto','sqrt','log2'],\n",
    "        'max_depth':[3,5,8,10],\n",
    "        'subsample':[0.8,1]\n",
    "    }\n",
    "    \n",
    "    grid_gbr = GridSearchCV(estimator = gbr,\n",
    "                           param_grid = params_gbr,\n",
    "                           scoring ='neg_mean_squared_error',\n",
    "                           cv = 3,\n",
    "                           verbose = 1,\n",
    "                           n_jobs = -1)\n",
    "    \n",
    "    grid_gbr.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    print('CV Score for best Grandient Boost Regressor model: {:.3f}'.format(cv_score(grid_gbr.best_score_)))\n",
    "    best_model = grid_gbr.best_estimator_\n",
    "    return best_model \n",
    "\n",
    "def rmse_dataframe(rmse):\n",
    "    \n",
    "    rmse_result = pd.DataFrame(rmse)\n",
    "    rmse_result['model'] = ['linear_regression',\n",
    "                            'ridge_regression',\n",
    "                            'decision_tree',\n",
    "                            'random_forest_regressor',\n",
    "                            'extra_tree_regressor',\n",
    "                            'gbr']\n",
    "    rmse_result.columns = ['rmse','model']\n",
    "    rmse_result = rmse_result[['model','rmse']]\n",
    "    \n",
    "    return rmse_result\n",
    "\n",
    "def prediction_dataframe(li,y_test):\n",
    "    df_predict = pd.DataFrame(li).T\n",
    "    df_predict['y_Test'] = pd.DataFrame(y_test)\n",
    "    df_predict.rename(columns={0:'linear_regression',\n",
    "                               1:'ridge_regression',\n",
    "                               2:'decision_tree',\n",
    "                               3:'random_forest_regressor',\n",
    "                               4:'extra_tree_regressor',\n",
    "                               5:'gbr',\n",
    "                               }, \n",
    "                             inplace=True)\n",
    "    return df_predict\n",
    "\n",
    "\n",
    "def model_selection(X,y, classifier):\n",
    "    \n",
    "    li = []\n",
    "    rmse = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.30,\n",
    "                                                        random_state=SEED)\n",
    "    \n",
    "    y_train, y_test = prep_target(queimadas[TARGET],y_train, y_test)\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier', classifier)])\n",
    "        \n",
    "        pipe.fit(X_train, y_train.ravel())\n",
    "    \n",
    "        print('\\n',classifier)\n",
    "        \n",
    "        pred_test = pipe.predict(X_test)\n",
    "        #pred_train = pipe.predict(X_train)\n",
    "        rmse_result = np.sqrt(mean_squared_error(y_test, pred_test))\n",
    "        \n",
    "        rmse.append(rmse_result)\n",
    "        li.append(pred_test)\n",
    "        \n",
    "        print('\\n TEST - Root Mean Squared Error: : {:.3f}'.format(rmse_result)) \n",
    "    \n",
    "    prediction_dataframe(li,y_test)\n",
    "    \n",
    "    return prediction_dataframe(li,y_test), rmse_dataframe(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TARGET = ['frp']\n",
    "#FEATURES = ['riscofogo','bioma','avg_temp_ar','avg_umd_ar','avg_vento_velo']\n",
    "\n",
    "FEATURES = ['diasemchuv','hora','mes','quadrimestre',\n",
    "            'avg_prep_total','avg_pressao_atm',\n",
    "            'avg_umd_ar','avg_temp_ar','avg_vento_velo']\n",
    "\n",
    "\n",
    "TARGET = ['riscofogo']\n",
    "#FEATURES = ['diasemchuv','mes','quadrimestre','avg_pressao_atm','avg_umd_ar','avg_temp_ar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]: Ler dados\n",
    "\n",
    "queimadas = read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]: Transformar dados\n",
    "X_train, X_test, y_train, y_test, preprocessor = prep_pipeline(queimadas[FEATURES],queimadas[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[5]: Escolher Modelos - Regressão Linear\n",
    "\n",
    "ln_model = get_linear_regressor(X_train,y_train)\n",
    "\n",
    "ln_ridge_model = get_ridge_regression(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]: Escolher Modelos - Arvore de Decisão Regressão\n",
    "\n",
    "dt_model = get_decisiontree_regressor(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[7]:  Escolher Modelos - RandomForestRegressor\n",
    "rf_model = get_rf_regressor(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[8]:  Escolher Modelos - ExtraTreeRegressor\n",
    "extreg_model = get_extratree_regressor(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[9]:  Escolher Modelos - Grandient Boost Regressor\n",
    "gbr_model = get_gbr_regressor(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[10]:  Escolher Modelos - Grandient Boost Regressor\n",
    "classifiers = [\n",
    "    ln_model,\n",
    "    ln_ridge_model,\n",
    "    dt_model,\n",
    "    rf_model,\n",
    "    extreg_model,\n",
    "    gbr_model\n",
    "    ]\n",
    "\n",
    "li, rmse = model_selection(queimadas[FEATURES],queimadas[TARGET],classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[11]: feature Importance\n",
    "\n",
    "feature_importances = rf_model.feature_importances_\n",
    "'''\n",
    "data = {'Features':['diasemchuv',\n",
    "                    'mes',\n",
    "                    'quadrimestre',\n",
    "                    'avg_pressao_atm',\n",
    "                    'avg_umd_ar'],\n",
    "        'Ratings':feature_importances}\n",
    "\n",
    "df_data = pd.DataFrame(data, index =['0', '1', '2', '3','4'])  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[10]: feature Importance\n",
    "\n",
    "fn=FEATURES\n",
    "cn=TARGET\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
    "tree.plot_tree(rf_model.estimators_[0],\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               rounded=True,\n",
    "               filled = True);\n",
    "fig.savefig('rf_individualtree.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
